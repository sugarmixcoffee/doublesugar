`머신러닝 알고리즘 프로젝트`

# **`산탄데르 고객만족 예측`**

## **`1 프로젝트 개요`** 

* `산탄데르 은행의 고객만족도 데이터로 고객만족 여부를 예측하는 프로젝트이다.`  
* `AUC가 높은 최적의 파라미터를 찾는 것을 목표로 한다. 성능 향상을 위해 HyperOpt를 사용하여 최적의 파라미터를 탐색하여 base 모델의 성능과 비교해보았며, L1, L2 규제를 추가하여 비교하였다.`

## **`2 데이터 개요`**

* `샘플 76020, 피쳐 371`  
* `Target : 레이블`  

  `0: 만족, 1: 불만 (73012, 3008)`

  `불만족 고객비율: 0.04`

* `레이블이 불균형하기 때문에 정확도보다 AUC가 더 적합하다.`  
* `피쳐명은 익명화되어 있다`  
* `문자열 데이터는 없음` 

## **`3 데이터 전처리`**

* `이상치제거`  
  * `var3 : -999999을(116개) 피처의 가장 많은 값(74165개) 2로 대체함`  
  * `고객id : 분석에 의미가 없으므로 삭제`

## **`4 사용 알고리즘`**

* `XGBoost`  
* `LightGBM`

## **`5 HyperOpt : Best 파라미터 찾기`**

#### **`평가기준`**

* `평가지표 : AUC`  
* `성능 : base모델과 비교하였다.`

### **`1.1 XGBoost 성능`** 

1) `base 모델 성능`  
   * `AUC : 0.8385`  
       
2) `hyperOpt 파라미터`  
   * `50/50 [10:14<00:00, 12.29s/trial, best loss: -0.8376812781104487]`  
     `AUC: 0.8376812781104487`  
   * `best:  {'colsample_bytree': np.float64(0.7182634686833416), 'learning_rate': np.float64(0.17378359656337916), 'max_depth': np.float64(5.0), 'min_child_weight': np.float64(5.0)}`

   `3) 베스트 파라미터를 적용한 결과`

* `AUC: 0.8385 → 0.8443로 증가`

### **`1.2 XGBoost : L1, L2 규제 추가`** 

1) `hyperOpt 파라미터`	  
* `50/50 [18:08<00:00, 21.76s/trial, best loss: -0.8381368482942128]`

  `AUC : 0.8381368482942128`

* `best:  {'colsample_bytree': np.float64(0.6775837584617517), 'learning_rate': np.float64(0.06914008982803578), 'max_depth': np.float64(5.0), 'min_child_weight': np.float64(7.0), 'reg_alpha': np.float64(1.219494561244686), 'reg_lambda': np.float64(7.17448849472397)}`


2) `베스트 파라미터 적용 결과`  
* `AUC: 0.8455`


### **`2.1 LightGBM 성능`** 

1) `base 모델 성능`  
   * `AUC : 0.8384`  
       
2) `hyperOpt 파라미터`	  
* `50/50 [02:04<00:00,  2.50s/trial, best loss: -0.835974683012816]`

  `AUC: 0.835974683012816`

* `best: {'learning_rate': np.float64(0.060410380599969726), 'max_depth': np.float64(122.0), 'min_child_samples': np.float64(87.0), 'num_leaves': np.float64(38.0), 'subsample': np.float64(0.7023057985957527)}`

3) `베스트 파라미터를 적용한 결과`  
* `AUC: 0.8384 → 0.8409로 증가`

### **`2.2 LightGBM : L1, L2 규제 추가`** 

1) `hyperOpt 파라미터`	  
* `50/50 [02:35<00:00,  3.10s/trial, best loss: -0.8362482450256886]`

  `AUC: 0.8362482450256886`

* `best: {'criterion': np.int64(1), 'learning_rate': np.float64(0.05865638926061394), 'max_depth': np.float64(128.0), 'min_child_samples': np.float64(82.0), 'num_leaves': np.float64(36.0), 'reg_alpha': np.float64(1.7490256033823903), 'reg_lambda': np.float64(8.07129528761313), 'subsample': np.float64(0.7625318975591606)}`  
2) `베스트 파라미터를 적용한 결과`  
* `AUC: 0.8440`

###### `참고) 코드`

`[\_산탄데르\_이현경.pdf](https://drive.google.com/file/d/1rsNhDNfij0Jl2PfiZ3nkP8dACCUFJWwt/view?usp=sharing)`

## **`6 결론`**

* `XGBoost 모델이 좀더 높은 AUC를 기록하였고 성능향상의 폭이 컸다.`    
* `L1, L2 규제를 추가하여 성능이 더 향상되는 것을 확인할 수 있었다.`   
* `개선할점: HyperOpt는 실행시마다 best 파라미터가 약간 달라질 수 있어서 공간설정에 대한 면밀한 검토가 필요하다.` 

